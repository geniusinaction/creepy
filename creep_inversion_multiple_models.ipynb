{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverting for surface creep rate from InSAR profile data\n",
    "\n",
    "Gareth Funning, University of California, Riverside\n",
    "\n",
    "This notebook takes profiles through InSAR velocity data from ascending and descending viewing geometries, and solves for the surface offset rate by fitting a step function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "0. [Dependencies](#dep)\n",
    "1. [InSAR velocity data](#InSAR)\n",
    "2. [Fault data wrangling](#fault)\n",
    "3. [Find average fault strike](#strike)\n",
    "4. [Interpolate fault segment data](#interpolate)\n",
    "5. [Projecting InSAR data onto a profile](#projecting)\n",
    "6. [Fitting straight lines to the profiles](#fitting)\n",
    "7. [The big loop](#bigloop)\n",
    "8. [Other outputs](#other)\n",
    "9. [References](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"dep\"></a>0. Dependencies\n",
    "\n",
    "This notebook makes use of a few dependencies. Make sure they're all installed before you get started, otherwise Jupyter will be sad...\n",
    "\n",
    "Other than some fairly standard libraries, you will need to download [interparc.py](https://github.com/rsyi/python-lib/blob/master/interparc.py) to your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from interparc import interparc\n",
    "import utm\n",
    "import matplotlib.pyplot as plt\n",
    "import pygmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"InSAR\"></a>1. InSAR velocity data \n",
    "\n",
    "In this exercise we are going to analyze pre-processed InSAR deformation velocities. These are supplied along with their corresponding line-of-sight (LOS) information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file names, directories, and sign convention\n",
    "asc_tr = 'A137'\n",
    "dsc_tr = 'D042'\n",
    "signconvention = -1   # 1 if data are in range change, -1 if they are ground displacement\n",
    "\n",
    "asc_file = '../' + asc_tr + '/vel/ARIA_' + asc_tr + '_vel_ll.grd'\n",
    "#asc_file = '../' + asc_tr + '_masked_ll.grd'\n",
    "asc_azi = '../LOSfiles_CA/' + asc_tr + '/LOS/ARIA_' + asc_tr + '_azimuthAngle_ll.grd'\n",
    "asc_inc = '../LOSfiles_CA/' + asc_tr + '/LOS/ARIA_' + asc_tr + '_incidenceAngle_ll.grd'\n",
    "\n",
    "dsc_file = '../' + dsc_tr + '/vel/ARIA_' + dsc_tr + '_vel_ll.grd'\n",
    "#dsc_file = '../'  + dsc_tr + '_masked_ll.grd'\n",
    "dsc_azi = '../LOSfiles_CA/' + dsc_tr + '/LOS/ARIA_' + dsc_tr + '_azimuthAngle_ll.grd'\n",
    "dsc_inc = '../LOSfiles_CA/' + dsc_tr + '/LOS/ARIA_' + dsc_tr + '_incidenceAngle_ll.grd'\n",
    "\n",
    "print('ascending track ' + asc_tr + ', data file: ' + asc_file)\n",
    "print('descending track ' + dsc_tr + ', data file: ' + dsc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"fault\"></a>2. Fault data wrangling\n",
    "\n",
    "Let's load in some fault location data, and figure out some points that we can use for profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some optional nonsense for prepping some fault data\n",
    "!rm doc.kml\n",
    "!unzip SanAndreas_shallow.kmz  # I crudely traced the fault with this Google Earth kmz line file\n",
    "!gmt kml2gmt doc.kml |  awk '{if (NR>1) print $0}' | sort -n > SanAndreas_shallow.xy  # grab some coordinates from it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some fault stuff\n",
    "infault='SanAndreas_shallow.xy' # a file of long-lat coordinates that are on the fault of interest\n",
    "\n",
    "# these two inputs can take multiple different values in array form\n",
    "box_hw=np.array([2, 4])        # the (strike-perpendicular) half width of the boxes in km\n",
    "mask_hw=np.array([0.2, 0.2])   # strike-perpendicular distance (in km) to mask out\n",
    "\n",
    "# these are fixed for the whole fault\n",
    "box_length=2            # (along-strike) length of the boxes in km\n",
    "pt_spacing=0.1          # sample spacing (km)\n",
    "\n",
    "buffer=0;    # x/y overlap between boxes\n",
    "\n",
    "# some coordinate business\n",
    "utm_zone = 10\n",
    "utm_letter = 'S' # consult here if unsure: http://maps.unomaha.edu/Peterson/gis/notes/MapProjCoord.html\n",
    "\n",
    "# here are some example coordinates\n",
    "fault_data_ll=np.loadtxt(infault)\n",
    "\n",
    "# transform fault coordinates into utm\n",
    "fault_data_utm=utm.from_latlon(fault_data_ll[:,1],fault_data_ll[:,0],utm_zone,utm_letter)\n",
    "eastings=fault_data_utm[0]\n",
    "northings=fault_data_utm[1]\n",
    "\n",
    "# extract line segments from the input vertices\n",
    "# utm outputs horizontal arrays, which we will have to deal with\n",
    "# np.vstack stacks them... -2 means to penultimate element, -1 means to last element\n",
    "# and transpose to make it columns again\n",
    "fault_segments=np.transpose(np.vstack((eastings[0:-1],northings[0:-1],eastings[1:],northings[1:])))\n",
    "\n",
    "# calculate total line length by doing pythagoras and summing! \n",
    "fault_length=np.sum(np.sqrt(np.square(fault_segments[:,2]-fault_segments[:,0])\n",
    "        +np.square(fault_segments[:,3]-fault_segments[:,1])))/1000\n",
    "\n",
    "# how many fault nodes do we need?\n",
    "nnodes = round(fault_length/(box_length))+1\n",
    "\n",
    "# and what is the node spacing?\n",
    "nspacing = fault_length/(nnodes-1)\n",
    "\n",
    "print('Fault length ' + str(round(fault_length,1)) + \n",
    "      ' km, we will use ' + str(nnodes) + ' nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"strike\"></a>3. Find the average fault strike\n",
    "\n",
    "I have had issues with projecting things into local strike-parallel velocity, so we will experiment with using just the average strike. Experimental!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to fit a best-fitting line to the fault vertices!\n",
    "A=np.transpose(np.vstack((eastings,np.ones(np.shape(eastings)))))   # form the design matrix\n",
    "ATAinv=np.linalg.inv(np.matmul(A.T,A))          # make and invert ATA in one go!\n",
    "m=np.matmul(ATAinv,np.matmul(A.T,northings))    # m is the model vector, the gradient and intercept of the best fit line\n",
    "av_str=np.degrees(np.arctan(1/m[0]))+180        # the arctan of the inverse gradient is the strike!\n",
    "\n",
    "print('Average strike is {0:6.2f} degrees'.format(av_str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"interpolate\"></a>4. Interpolate fault segment data\n",
    "\n",
    "We need to calculate some things about the fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next, interpolate the coordinates of yer fault\n",
    "\n",
    "node_utm=interparc(nnodes,eastings,northings)\n",
    "node_ll=utm.to_latlon(node_utm[:,0],node_utm[:,1],utm_zone,utm_letter)\n",
    "\n",
    "seg_verts=np.transpose(np.vstack((node_utm[0:-1,0],node_utm[0:-1,1],node_utm[1:,0],node_utm[1:,1])))\n",
    "\n",
    "# calculate strike\n",
    "stk=np.degrees(np.arctan2(seg_verts[:,2]-seg_verts[:,0],seg_verts[:,3]-seg_verts[:,1]))\n",
    "\n",
    "#\n",
    "seg_centers_utm=np.array(([(seg_verts[:,2]+seg_verts[:,0])/2,(seg_verts[:,3]+seg_verts[:,1])/2]))\n",
    "seg_centers_ll=utm.to_latlon(seg_centers_utm[0],seg_centers_utm[1],utm_zone,utm_letter)\n",
    "\n",
    "# tot up the along-profile distance\n",
    "seg_dist=np.arange(0,nnodes-1)*nspacing\n",
    "\n",
    "# make a data frame to put things in    \n",
    "fault_segs=pd.DataFrame({'longitude': seg_centers_ll[1], 'latitude': seg_centers_ll[0], \n",
    "                         'x': seg_centers_utm[0], 'y': seg_centers_utm[1], 'distance': seg_dist, 'strike': stk})\n",
    "\n",
    "# and we'll sample the LOS information at the centers\n",
    "fault_segs=pygmt.grdtrack(fault_segs,asc_azi,newcolname='asc_azi',interpolation=\"n\")\n",
    "fault_segs=pygmt.grdtrack(fault_segs,asc_inc,newcolname='asc_inc',interpolation=\"n\")\n",
    "fault_segs=pygmt.grdtrack(fault_segs,dsc_azi,newcolname='dsc_azi',interpolation=\"n\")\n",
    "fault_segs=pygmt.grdtrack(fault_segs,dsc_inc,newcolname='dsc_inc',interpolation=\"n\")\n",
    "\n",
    "# we'll ignore rows that contain zeros in the new data columns\n",
    "fault_segs=fault_segs.loc[(fault_segs[['asc_azi']] != 0).any(axis=1)]\n",
    "fault_segs=fault_segs.loc[(fault_segs[['dsc_azi']] != 0).any(axis=1)]\n",
    "\n",
    "# and reindex the data frame after throwing out the blanks\n",
    "fault_segs=fault_segs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_segs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"projecting\"></a>5. Projecting InSAR data onto a profile\n",
    "\n",
    "We will try and use the PyGMT command 'grdtrack' to sample these data files. grdtrack reads coordinates from text files or pandas data frames, and we will generate one of the latter. \n",
    "\n",
    "The first step is to ingest fault data, convert the locations into UTM (a rectilinear local coordinate system, which is more appropriate for this sort of analysis) and calculate the average strike:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will construct the profile coordinates. We'll pick the middle of the fault as our profile location. Once we specify dimensions of an area to sample, we will calculate the coordinates of a grid of points that we will use to sample the data files, project them back into geographical coordinates, and put them into a data frame. Simple (if a bit fiddly)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pick a profile location and length\n",
    "prof_num=21    # profile number\n",
    "plen=1        # index of the profile length you want\n",
    "\n",
    "prof_x=fault_segs.iloc[prof_num][\"x\"]    # x coordinate of profile center (in UTM) \n",
    "prof_y=fault_segs.iloc[prof_num][\"y\"]    # y coordinate \n",
    "fault_strike=fault_segs.iloc[prof_num][\"strike\"]\n",
    "\n",
    "# unit vector in the along-strike direction\n",
    "fault_dx=np.sin(np.radians(fault_strike))\n",
    "fault_dy=np.cos(np.radians(fault_strike))\n",
    "\n",
    "# unit vector in the along-profile direction (90 degrees from strike)\n",
    "prof_dx=np.sin(np.radians(fault_strike-90))\n",
    "prof_dy=np.cos(np.radians(fault_strike-90))\n",
    "\n",
    "# let's make vectors of along-profile and cross-profile distances\n",
    "p=np.linspace(-box_hw[plen],box_hw[plen],round(2*box_hw[plen]/pt_spacing)+1)  #  p = along-profile distance\n",
    "q=np.linspace(-box_length/2,box_length/2,round(box_length/pt_spacing)+1)      # q = cross-profile distance\n",
    "vp=np.linspace(-box_hw[plen],box_hw[plen],2)                # the p coordinates of the corners of the profile\n",
    "vq=np.linspace(-box_length/2,box_length/2,2)                # the q coordinates of the corners of the profile\n",
    "\n",
    "# we can make grids of points in (p,q) coordinates\n",
    "P, Q = np.meshgrid(p,q)                 # all the points we want to sample\n",
    "VP = np.array([[vp], [np.flip(vp)]])    # the vertices of the area being sampled\n",
    "VQ = np.array([[vq], [vq]]).T\n",
    "\n",
    "# transform these coordinates into UTM\n",
    "X=prof_x+P*prof_dx*1000+Q*fault_dx*1000       # x coordinates (in UTM) of sample points \n",
    "Y=prof_y+P*prof_dy*1000+Q*fault_dy*1000       # y coordinates (in UTM) of sample points\n",
    "VX=prof_x+VP*prof_dx*1000+VQ*fault_dx*1000    # x coordinates of sample region vertices\n",
    "VY=prof_y+VP*prof_dy*1000+VQ*fault_dy*1000    # y coordinates of sample region vertices\n",
    "\n",
    "# let's get the UTM coordinates for the profile line, too\n",
    "px=prof_x+1000*prof_dx*vp\n",
    "py=prof_y+1000*prof_dy*vp\n",
    "\n",
    "# flattening grids into single columns,  transform these into lat-long\n",
    "pt_locs_ll=utm.to_latlon(X.reshape(-1),Y.reshape(-1),utm_zone,utm_letter)\n",
    "vt_locs_ll=utm.to_latlon(VX.reshape(-1),VY.reshape(-1),utm_zone,utm_letter)\n",
    "pf_locs_ll=utm.to_latlon(px,py,utm_zone,utm_letter)\n",
    "pf_center_ll=utm.to_latlon(prof_x,prof_y,utm_zone,utm_letter)\n",
    "\n",
    "# let's make data frames for these\n",
    "samp_pts=pd.DataFrame({'longitude': pt_locs_ll[1], 'latitude': pt_locs_ll[0], 'P': P.reshape(-1), 'Q': Q.reshape(-1)})\n",
    "samp_vts=pd.DataFrame({'longitude': vt_locs_ll[1], 'latitude': vt_locs_ll[0], 'P': VP.reshape(-1), 'Q': VQ.reshape(-1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can see what these data frames look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the profile and sample area on a map!\n",
    "\n",
    "# set bounds\n",
    "study_region=[-121.8,-120,35.5,37.0]  # [west, east, south, north]\n",
    "\n",
    "# initiate a PyGMT figure \n",
    "fig = pygmt.Figure() \n",
    "\n",
    "# override some ugly (I think) defaults:\n",
    "pygmt.config(FORMAT_GEO_MAP=\"ddd.x\")\n",
    "\n",
    "# make a colormap\n",
    "pygmt.makecpt(cmap='polar', series=(-15, 15, 0.5), background=\"o\")\n",
    "\n",
    "# and let's get plotting!\n",
    "fig.basemap(region=study_region, projection=\"M12c\", frame=[\"a1f0.2\",\"WeSn\"])  # make a basemap frame\n",
    "fig.grdimage(asc_file)                                                        # plot one data file\n",
    "fig.coast(shorelines=[\"1/1p,navy\",\"2/1p,navy\"], borders=[\"1/0.5p,darkred\"])   # coasts and borders\n",
    "fig.text(text=asc_tr, position=\"BL\", font=\"14p\", offset=\"0.2c\", justify=\"BL\") # label the plot\n",
    "fig.plot(x=samp_vts[\"longitude\"],y=samp_vts[\"latitude\"], pen=\"1p,black\",close=True)   # sample box\n",
    "fig.plot(x=node_ll[1],y=node_ll[0],pen=\"1.5p,gray50\")              # fault trace\n",
    "\n",
    "fig.shift_origin(xshift=\"14c\")                                                # shift the origin\n",
    "fig.basemap(region=study_region, projection=\"M12c\", frame=[\"a1f0.2\",\"weSn\"])  # and let's make another one!\n",
    "fig.grdimage(dsc_file)                                                        # plot the other file\n",
    "fig.coast(shorelines=[\"1/1p,navy\",\"2/1p,navy\"], borders=[\"1/0.5p,darkred\"])   # coasts and borders\n",
    "fig.text(text=dsc_tr, position=\"BL\", font=\"14p\", offset=\"0.2c\", justify=\"BL\") # label this one too\n",
    "fig.plot(x=samp_vts[\"longitude\"],y=samp_vts[\"latitude\"], pen=\"1p,black\",close=True)   # sample box\n",
    "fig.plot(x=node_ll[1],y=node_ll[0],pen=\"1.5p,gray50\")              # fault trace\n",
    "\n",
    "# and display!\n",
    "fig.show(width=800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look good? Then we shall proceed with data sampling! As mentioned, we will use pygmt.grdtrack to do this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes nothing!\n",
    "samp_pts=pygmt.grdtrack(samp_pts,asc_file,newcolname=asc_tr,interpolation=\"n\")  # add a column for the ascending data\n",
    "samp_pts=pygmt.grdtrack(samp_pts,dsc_file,newcolname=dsc_tr,interpolation=\"n\")  # add a column for the descending data\n",
    "\n",
    "# we'll ignore rows that contain zeros in the two new data columns\n",
    "samp_pts=samp_pts.loc[(samp_pts[[asc_tr, dsc_tr]] != 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy! The effect is to add a couple of extra columns to 'samp_pts'. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at the values by plotting them with matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initiate the plot\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# plot the data as red inverted triangles with 2-sigma error bars\n",
    "plt.scatter(samp_pts[\"P\"], samp_pts[asc_tr], marker=\".\", label=asc_tr)  \n",
    "plt.scatter(samp_pts[\"P\"], samp_pts[dsc_tr], marker=\".\", label=dsc_tr)  \n",
    "    \n",
    "# add some labels\n",
    "plt.xlabel(\"x (km)\")\n",
    "plt.ylabel(\"v (mm/yr)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_azi=fault_segs.iloc[prof_num][\"asc_azi\"]\n",
    "asc_inc=fault_segs.iloc[prof_num][\"asc_inc\"]\n",
    "dsc_azi=fault_segs.iloc[prof_num][\"dsc_azi\"]\n",
    "dsc_inc=fault_segs.iloc[prof_num][\"dsc_inc\"]\n",
    "\n",
    "# calculate the unit LOS vectors (satellite pointing to ground target)\n",
    "asc_los=np.array([np.sin(np.radians(asc_azi))*np.sin(np.radians(asc_inc)),\n",
    "                  -np.cos(np.radians(asc_azi))*np.sin(np.radians(asc_inc)),\n",
    "                  -np.cos(np.radians(asc_inc))])*signconvention\n",
    "\n",
    "dsc_los=np.array([np.sin(np.radians(dsc_azi))*np.sin(np.radians(dsc_inc)),\n",
    "                  -np.cos(np.radians(dsc_azi))*np.sin(np.radians(dsc_inc)),\n",
    "                  -np.cos(np.radians(dsc_inc))])*signconvention\n",
    "\n",
    "# report the sign convention\n",
    "if signconvention==1:\n",
    "    print('range change sign convention')\n",
    "elif signconvention==-1:\n",
    "    print('ground displacement sign convention')\n",
    "else:\n",
    "    print('you may have messed up this sign convention thing, to be honest')\n",
    "\n",
    "# and report your LOS vector\n",
    "print('ascending track LOS vector: [{0:5.3f}, {1:5.3f}, {2:5.3f}]'.format(asc_los[0],asc_los[1],asc_los[2]))\n",
    "print('descending track LOS vector: [{0:5.3f}, {1:5.3f}, {2:5.3f}]'.format(dsc_los[0],dsc_los[1],dsc_los[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"fitting\"></a>6. Fitting straight lines to the profiles\n",
    "\n",
    "We still have a few steps to go in order to estimate surface creep rate from the InSAR data. Next, we need to try and fit the step function to both profiles simultaneously. Could be fun!\n",
    "\n",
    "We can try some forward models, first, and project them into the LOS directions we have just calculated. Recall that the 1D model deals with fault-parallel velocities, so we need to consider the direction of fault-parallel motion (the along-strike unit vector) when doing this $-$ we need to take the dot product between the along-strike unit vector and the LOS vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the window of data we want to fit\n",
    "prof_1=samp_pts.loc[(samp_pts['P'] >= -box_hw[plen]) & (samp_pts['P'] <= -mask_hw[plen])]\n",
    "prof_2=samp_pts.loc[(samp_pts['P'] >= mask_hw[plen]) & (samp_pts['P'] <= box_hw[plen])]\n",
    "\n",
    "# set up the ascending data set inversion\n",
    "A_asc=np.vstack((np.transpose(np.vstack((prof_1['P'],np.ones(np.shape(prof_1['P'])),np.zeros(np.shape(prof_1['P']))))),\n",
    "                 np.transpose(np.vstack((prof_2['P'],np.zeros(np.shape(prof_2['P'])),np.ones(np.shape(prof_2['P'])))))))\n",
    "d_asc=np.concatenate([prof_1[asc_tr],prof_2[asc_tr]])\n",
    "\n",
    "# set up the descending data set inversion\n",
    "A_dsc=np.vstack((np.transpose(np.vstack((prof_1['P'],np.ones(np.shape(prof_1['P'])),np.zeros(np.shape(prof_1['P']))))),\n",
    "                 np.transpose(np.vstack((prof_2['P'],np.zeros(np.shape(prof_2['P'])),np.ones(np.shape(prof_2['P'])))))))\n",
    "d_dsc=np.concatenate([prof_1[dsc_tr],prof_2[dsc_tr]])\n",
    "\n",
    "# invert for ascending offset rate \n",
    "ATAinv_asc=np.linalg.inv(np.matmul(A_asc.T,A_asc))    # make and invert ATA in one go!\n",
    "m_asc=np.matmul(ATAinv_asc,np.matmul(A_asc.T,d_asc))  # m_asc is the model vector\n",
    "\n",
    "# misfit!\n",
    "dprime_asc=np.matmul(A_asc,m_asc)\n",
    "res_asc=d_asc-dprime_asc\n",
    "rms_asc=np.sqrt(np.matmul(res_asc.T,res_asc)/np.size(res_asc))\n",
    "\n",
    "# invert for descending offset rate \n",
    "ATAinv_dsc=np.linalg.inv(np.matmul(A_dsc.T,A_dsc))    # make and invert ATA in one go!\n",
    "m_dsc=np.matmul(ATAinv_dsc,np.matmul(A_dsc.T,d_dsc))  # m_dsc is the model vector\n",
    "\n",
    "# misfit!\n",
    "dprime_dsc=np.matmul(A_dsc,m_dsc)\n",
    "res_dsc=d_dsc-dprime_dsc\n",
    "rms_dsc=np.sqrt(np.matmul(res_dsc.T,res_dsc)/np.size(res_dsc))\n",
    "\n",
    "# collate and report the results\n",
    "asc_offset=m_asc[2]-m_asc[1]\n",
    "sigma_asc_offset=np.sqrt(ATAinv_asc[1,1]+ATAinv_asc[2,2])\n",
    "dsc_offset=m_dsc[2]-m_dsc[1]\n",
    "sigma_dsc_offset=np.sqrt(ATAinv_dsc[1,1]+ATAinv_dsc[2,2])\n",
    "print(\"profile {0:d}\".format(prof_num))\n",
    "print(\"ascending offset rate {0:4.1f} +/- {1:3.1f} (2-sigma), descending offset rate {2:4.1f} +/- {3:3.1f} (2-sigma)\"\n",
    "      .format(asc_offset,2*sigma_asc_offset,dsc_offset,2*sigma_dsc_offset))\n",
    "print(\"ascending rms {0:4.1f}, descending rms {1:4.1f}\".format(rms_asc,rms_dsc))\n",
    "\n",
    "\n",
    "# and let's estimate a creep rate! set up matrices and vectors:\n",
    "A_creep=np.vstack(([fault_dx*asc_los[0]+fault_dy*asc_los[1], asc_los[2]],\n",
    "                    [fault_dx*dsc_los[0]+fault_dy*dsc_los[1], dsc_los[2]]))\n",
    "d_creep=np.vstack(([asc_offset],[dsc_offset]))\n",
    "Einv_creep=np.vstack(([1/sigma_asc_offset**2, 0],[0, 1/sigma_dsc_offset**2]))\n",
    "\n",
    "# and the normal equations, etc\n",
    "ATAinv_creep=np.linalg.inv(np.matmul(np.matmul(A_creep.T,Einv_creep),A_creep))\n",
    "ATd_creep=np.matmul(np.matmul(A_creep.T,Einv_creep),d_creep)\n",
    "\n",
    "# and solve!\n",
    "m_creep=np.matmul(ATAinv_creep,ATd_creep)\n",
    "\n",
    "h_offset=m_creep[0]\n",
    "sigma_h_offset=np.sqrt(ATAinv_creep[0,0])\n",
    "v_offset=m_creep[1]\n",
    "sigma_v_offset=np.sqrt(ATAinv_creep[1,1])\n",
    "print(\"fault-parallel offset rate {0:5.1f} +/- {1:3.1f} (2-sigma), vertical offset rate {2:5.1f} +/- {3:3.1f} (2-sigma)\"\n",
    "      .format(h_offset[0],2*sigma_h_offset,v_offset[0],2*sigma_v_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, let's detrend our data and plot them\n",
    "\n",
    "abox=[-box_hw[plen], box_hw[plen], -15, 10]\n",
    "dbox=[-box_hw[plen], box_hw[plen], -5, 20]\n",
    "\n",
    "fig = pygmt.Figure() \n",
    "\n",
    "# and let's get plotting!\n",
    "fig.basemap(region=abox, projection=\"X12c/6c\", \n",
    "            frame=['xa1f0.2+l\"distance (km)\"','ya10f2+l\"los velocity (mm/yr)\"',\"WeSn\"])  # make a basemap frame\n",
    "fig.text(text='{0:s}, {1:4.1f} +/- {2:3.1f}'.format(asc_tr,asc_offset,2*sigma_asc_offset), position=\"TL\", font=\"14p\", \n",
    "         offset=\"0.2c/-0.2c\", justify=\"TL\") # label the plot\n",
    "fig.text(text='rms: {0:4.1f}'.format(rms_asc), position=\"TR\", font=\"14p\", offset=\"-0.2c/-0.2c\", justify=\"TR\") # label the plot\n",
    "fig.text(text=\"profile {0:d}\".format(prof_num), position=\"BL\", font=\"14p\", offset=\"0.2c\", justify=\"BL\") # label the plot\n",
    "fig.plot(x=samp_pts[\"P\"],y=samp_pts[asc_tr]-m_asc[0]*samp_pts[\"P\"]-m_asc[1], style=\"c0.1c\", color=\"cyan\")   # detrended velocities\n",
    "fig.plot(x=[-box_hw[plen], -mask_hw[plen]],y=[0,0], pen='2p,black,-')\n",
    "fig.plot(x=[-mask_hw[plen], 0],y=[0,0], pen='2p,black,.')\n",
    "fig.plot(x=[0, mask_hw[plen]],y=[asc_offset,asc_offset], pen='2p,black,.')\n",
    "fig.plot(x=[mask_hw[plen], box_hw[plen]],y=[asc_offset,asc_offset], pen='2p,black,-')\n",
    "\n",
    "\n",
    "fig.shift_origin(xshift=\"14c\")                                                # shift the origin\n",
    "fig.basemap(region=dbox, projection=\"X12c/6c\", frame=['xa1f0.2+l\"distance (km)\"','ya10f2','WeSn'])  # make a basemap frame\n",
    "fig.text(text='{0:s}, {1:4.1f} +/- {2:3.1f}'.format(dsc_tr,dsc_offset,2*sigma_dsc_offset), position=\"TL\", font=\"14p\", \n",
    "         offset=\"0.2c/-0.2c\", justify=\"TL\") # label the plot\n",
    "fig.text(text='rms: {0:4.1f}'.format(rms_dsc), position=\"TR\", font=\"14p\", offset=\"-0.2c/-0.2c\", justify=\"TR\") # label the plot\n",
    "fig.text(text=\"creep: {0:4.1f} +/- {1:3.1f}\".format(h_offset[0],2*sigma_h_offset), position=\"BR\", font=\"14p\", \n",
    "         offset=\"-0.2c/0.2c\", justify=\"BR\") # label the plot\n",
    "fig.plot(x=samp_pts[\"P\"], y=samp_pts[dsc_tr]-m_dsc[0]*samp_pts[\"P\"]-m_dsc[1], style=\"c0.1c\", color=\"orange\")  # detrended velocities\n",
    "fig.plot(x=[-box_hw[plen], -mask_hw[plen]], y=[0,0], pen='2p,black,-')\n",
    "fig.plot(x=[-mask_hw[plen], 0], y=[0,0], pen='2p,black,.')\n",
    "fig.plot(x=[0, mask_hw[plen]], y=[dsc_offset,dsc_offset], pen='2p,black,.')\n",
    "fig.plot(x=[mask_hw[plen], box_hw[plen]],y=[dsc_offset,dsc_offset], pen='2p,black,-')\n",
    "\n",
    "\n",
    "fig.show(width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"bigloop\"></a>7. The big loop\n",
    "\n",
    "Having tested all the parts of the process: estimating geometry, constructing profiles, sampling data, fitting lines, inverting for creep rate... the next step is to apply the whole process to every profile, in a monster loop. We will store all the results in another pandas data frame, and output every profile plot as an image file. Stand by..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plen=0       # choose which profile_length to use\n",
    "\n",
    "print('profile half-width = {0:f} km'.format(box_hw[plen]))\n",
    "print('mask half-width = {0:f} km'.format(mask_hw[plen]))\n",
    "\n",
    "# make a data frame to store results\n",
    "creep_rates=pd.DataFrame({'distance': fault_segs[\"distance\"], 'strike': fault_segs[\"strike\"], \n",
    "                          \"{0:s}_offset\".format(asc_tr): np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"{0:s}_sigma\".format(asc_tr): np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"{0:s}_rms\".format(asc_tr): np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"{0:s}_offset\".format(dsc_tr): np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"{0:s}_sigma\".format(dsc_tr): np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"{0:s}_rms\".format(dsc_tr): np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"fp_offset\": np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"fp_sigma\": np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"v_offset\": np.zeros(np.shape(fault_segs[\"strike\"])),\n",
    "                          \"v_sigma\": np.zeros(np.shape(fault_segs[\"strike\"])) })\n",
    "\n",
    "# for profile plotting later on\n",
    "abox=[-box_hw[plen], box_hw[plen], -15, 10]\n",
    "dbox=[-box_hw[plen], box_hw[plen], -5, 20]\n",
    "\n",
    "# let's do the big loop!\n",
    "for i, row in fault_segs.iterrows():\n",
    "    \n",
    "    prof_num=i\n",
    "    print(\"profile {0:d}\".format(prof_num))\n",
    "    \n",
    "    prof_x=fault_segs.iloc[prof_num][\"x\"]    # x coordinate of profile center (in UTM) \n",
    "    prof_y=fault_segs.iloc[prof_num][\"y\"]    # y coordinate \n",
    "    fault_strike=fault_segs.iloc[prof_num][\"strike\"]\n",
    "    as_distance=fault_segs.iloc[prof_num][\"distance\"] \n",
    "\n",
    "    # unit vector in the along-strike direction\n",
    "    fault_dx=np.sin(np.radians(fault_strike))\n",
    "    fault_dy=np.cos(np.radians(fault_strike))\n",
    "\n",
    "    # unit vector in the along-profile direction (90 degrees from strike)\n",
    "    prof_dx=np.sin(np.radians(fault_strike-90))\n",
    "    prof_dy=np.cos(np.radians(fault_strike-90))\n",
    "\n",
    "    # let's make vectors of along-profile and cross-profile distances\n",
    "    p=np.linspace(-box_hw[plen],box_hw[plen],round(2*box_hw[plen]/pt_spacing)+1)    #  p = along-profile distance\n",
    "    q=np.linspace(-box_length/2,box_length/2,round(box_length/pt_spacing)+1)        # q = cross-profile distance\n",
    "    vp=np.linspace(-box_hw[plen],box_hw[plen],2)                # the p coordinates of the corners of the profile\n",
    "    vq=np.linspace(-box_length/2,box_length/2,2)                # the q coordinates of the corners of the profile\n",
    "\n",
    "    # we can make grids of points in (p,q) coordinates\n",
    "    P, Q = np.meshgrid(p,q)                 # all the points we want to sample\n",
    "    VP = np.array([[vp], [np.flip(vp)]])    # the vertices of the area being sampled\n",
    "    VQ = np.array([[vq], [vq]]).T\n",
    "\n",
    "    # transform these coordinates into UTM\n",
    "    X=prof_x+P*prof_dx*1000+Q*fault_dx*1000       # x coordinates (in UTM) of sample points \n",
    "    Y=prof_y+P*prof_dy*1000+Q*fault_dy*1000       # y coordinates (in UTM) of sample points\n",
    "    VX=prof_x+VP*prof_dx*1000+VQ*fault_dx*1000    # x coordinates of sample region vertices\n",
    "    VY=prof_y+VP*prof_dy*1000+VQ*fault_dy*1000    # y coordinates of sample region vertices\n",
    "\n",
    "    # let's get the UTM coordinates for the profile line, too\n",
    "    px=prof_x+1000*prof_dx*vp\n",
    "    py=prof_y+1000*prof_dy*vp\n",
    "\n",
    "    # flattening grids into single columns,  transform these into lat-long\n",
    "    pt_locs_ll=utm.to_latlon(X.reshape(-1),Y.reshape(-1),utm_zone,utm_letter)\n",
    "    vt_locs_ll=utm.to_latlon(VX.reshape(-1),VY.reshape(-1),utm_zone,utm_letter)\n",
    "    pf_locs_ll=utm.to_latlon(px,py,utm_zone,utm_letter)\n",
    "    pf_center_ll=utm.to_latlon(prof_x,prof_y,utm_zone,utm_letter)\n",
    "\n",
    "    # let's make data frames for these\n",
    "    samp_pts=pd.DataFrame({'longitude': pt_locs_ll[1], 'latitude': pt_locs_ll[0], 'P': P.reshape(-1), 'Q': Q.reshape(-1)})\n",
    "    samp_vts=pd.DataFrame({'longitude': vt_locs_ll[1], 'latitude': vt_locs_ll[0], 'P': VP.reshape(-1), 'Q': VQ.reshape(-1)})\n",
    "\n",
    "    # here goes nothing!\n",
    "    samp_pts=pygmt.grdtrack(samp_pts,asc_file,newcolname=asc_tr,interpolation=\"n\")  # add a column for the ascending data\n",
    "    samp_pts=pygmt.grdtrack(samp_pts,dsc_file,newcolname=dsc_tr,interpolation=\"n\")  # add a column for the descending data\n",
    "\n",
    "    # we'll ignore rows that contain zeros in the two new data columns\n",
    "    samp_pts=samp_pts.loc[(samp_pts[[asc_tr, dsc_tr]] != 0).all(axis=1)]\n",
    "    \n",
    "    # azimuths and incidences\n",
    "    asc_azi=fault_segs.iloc[prof_num][\"asc_azi\"]\n",
    "    asc_inc=fault_segs.iloc[prof_num][\"asc_inc\"]\n",
    "    dsc_azi=fault_segs.iloc[prof_num][\"dsc_azi\"]\n",
    "    dsc_inc=fault_segs.iloc[prof_num][\"dsc_inc\"]\n",
    "\n",
    "    # calculate the unit LOS vectors (satellite pointing to ground target)\n",
    "    asc_los=np.array([np.sin(np.radians(asc_azi))*np.sin(np.radians(asc_inc)),\n",
    "                  -np.cos(np.radians(asc_azi))*np.sin(np.radians(asc_inc)),\n",
    "                  -np.cos(np.radians(asc_inc))])*signconvention\n",
    "\n",
    "    dsc_los=np.array([np.sin(np.radians(dsc_azi))*np.sin(np.radians(dsc_inc)),\n",
    "                  -np.cos(np.radians(dsc_azi))*np.sin(np.radians(dsc_inc)),\n",
    "                  -np.cos(np.radians(dsc_inc))])*signconvention\n",
    "\n",
    "    # extract the window of data we want to fit\n",
    "    prof_1=samp_pts.loc[(samp_pts['P'] >= -box_hw[plen]) & (samp_pts['P'] <= -mask_hw[plen])]\n",
    "    prof_2=samp_pts.loc[(samp_pts['P'] >= mask_hw[plen]) & (samp_pts['P'] <= box_hw[plen])]\n",
    "\n",
    "    # sanity check for data coverage\n",
    "    if prof_1.empty:\n",
    "        print('prof_1 is empty, skipping')\n",
    "        continue\n",
    "    if prof_2.empty:\n",
    "        print('prof_2 is empty, skipping')\n",
    "        continue\n",
    "    \n",
    "    # set up the ascending data set inversion\n",
    "    A_asc=np.vstack((np.transpose(np.vstack((prof_1['P'],np.ones(np.shape(prof_1['P'])),np.zeros(np.shape(prof_1['P']))))),\n",
    "                 np.transpose(np.vstack((prof_2['P'],np.zeros(np.shape(prof_2['P'])),np.ones(np.shape(prof_2['P'])))))))\n",
    "    d_asc=np.concatenate([prof_1[asc_tr],prof_2[asc_tr]])\n",
    "\n",
    "    # set up the descending data set inversion\n",
    "    A_dsc=np.vstack((np.transpose(np.vstack((prof_1['P'],np.ones(np.shape(prof_1['P'])),np.zeros(np.shape(prof_1['P']))))),\n",
    "                 np.transpose(np.vstack((prof_2['P'],np.zeros(np.shape(prof_2['P'])),np.ones(np.shape(prof_2['P']))))))) \n",
    "    d_dsc=np.concatenate([prof_1[dsc_tr],prof_2[dsc_tr]])\n",
    "\n",
    "    # invert for ascending offset rate \n",
    "    ATAinv_asc=np.linalg.inv(np.matmul(A_asc.T,A_asc))    # make and invert ATA in one go!\n",
    "    m_asc=np.matmul(ATAinv_asc,np.matmul(A_asc.T,d_asc))  # m_asc is the model vector\n",
    "\n",
    "    # misfit!\n",
    "    dprime_asc=np.matmul(A_asc,m_asc)\n",
    "    res_asc=d_asc-dprime_asc\n",
    "    rms_asc=np.sqrt(np.matmul(res_asc.T,res_asc)/np.size(res_asc))\n",
    "\n",
    "    # invert for descending offset rate \n",
    "    ATAinv_dsc=np.linalg.inv(np.matmul(A_dsc.T,A_dsc))    # make and invert ATA in one go!\n",
    "    m_dsc=np.matmul(ATAinv_dsc,np.matmul(A_dsc.T,d_dsc))  # m_dsc is the model vector\n",
    "    \n",
    "    # misfit!\n",
    "    dprime_dsc=np.matmul(A_dsc,m_dsc)\n",
    "    res_dsc=d_dsc-dprime_dsc\n",
    "    rms_dsc=np.sqrt(np.matmul(res_dsc.T,res_dsc)/np.size(res_dsc))\n",
    "\n",
    "    # collate and report the results\n",
    "    asc_offset=m_asc[2]-m_asc[1]\n",
    "    sigma_asc_offset=np.sqrt(ATAinv_asc[1,1]+ATAinv_asc[2,2])\n",
    "    dsc_offset=m_dsc[2]-m_dsc[1]\n",
    "    sigma_dsc_offset=np.sqrt(ATAinv_dsc[1,1]+ATAinv_dsc[2,2])\n",
    "    print(\"ascending offset rate {0:4.1f} +/- {1:3.1f} (2-sigma), descending offset rate {2:4.1f} +/- {3:3.1f} (2-sigma)\"\n",
    "      .format(asc_offset,2*sigma_asc_offset,dsc_offset,2*sigma_dsc_offset))\n",
    "\n",
    "\n",
    "    # and let's estimate a creep rate! set up matrices and vectors:\n",
    "    A_creep=np.vstack(([fault_dx*asc_los[0]+fault_dy*asc_los[1], asc_los[2]],\n",
    "                    [fault_dx*dsc_los[0]+fault_dy*dsc_los[1], dsc_los[2]]))\n",
    "    d_creep=np.vstack(([asc_offset],[dsc_offset]))\n",
    "    Einv_creep=np.vstack(([1/sigma_asc_offset**2, 0],[0, 1/sigma_dsc_offset**2]))\n",
    "\n",
    "    # and the normal equations, etc\n",
    "    ATAinv_creep=np.linalg.inv(np.matmul(np.matmul(A_creep.T,Einv_creep),A_creep))\n",
    "    ATd_creep=np.matmul(np.matmul(A_creep.T,Einv_creep),d_creep)\n",
    "\n",
    "    # and solve!\n",
    "    m_creep=np.matmul(ATAinv_creep,ATd_creep)\n",
    "\n",
    "    h_offset=m_creep[0]\n",
    "    sigma_h_offset=np.sqrt(ATAinv_creep[0,0])\n",
    "    v_offset=m_creep[1]\n",
    "    sigma_v_offset=np.sqrt(ATAinv_creep[1,1])\n",
    "    print(\"fault-parallel offset rate {0:5.1f} +/- {1:3.1f} (2-sigma), vertical offset rate {2:5.1f} +/- {3:3.1f} (2-sigma)\"\n",
    "      .format(h_offset[0],2*sigma_h_offset,v_offset[0],2*sigma_v_offset))\n",
    "    \n",
    "    \n",
    "    # finally, plot it\n",
    "    fig = pygmt.Figure() \n",
    "    \n",
    "    fig.basemap(region=abox, projection=\"X12c/6c\", \n",
    "            frame=['xa1f0.2+l\"distance (km)\"','ya10f2+l\"los velocity (mm/yr)\"',\"WeSn\"])  # make a basemap frame\n",
    "    fig.text(text='{0:s}, {1:4.1f} +/- {2:3.1f}'.format(asc_tr,asc_offset,2*sigma_asc_offset), position=\"TL\", font=\"14p\", \n",
    "         offset=\"0.2c/-0.2c\", justify=\"TL\") # label the plot\n",
    "    fig.text(text='rms: {0:4.1f}'.format(rms_asc), position=\"TR\", font=\"14p\", offset=\"-0.2c/-0.2c\", justify=\"TR\") \n",
    "    fig.text(text=\"d = {0:6.2f} km\".format(as_distance), position=\"BL\", \n",
    "             font=\"14p\", offset=\"0.2c\", justify=\"BL\") # label the plot\n",
    "    fig.plot(x=samp_pts[\"P\"], y=samp_pts[asc_tr]-m_asc[0]*samp_pts[\"P\"]-m_asc[1], style=\"c0.1c\", color=\"cyan\")   # detrended vels\n",
    "    fig.plot(x=[-box_hw[plen], -mask_hw[plen]], y=[0,0], pen='2p,black,-')\n",
    "    fig.plot(x=[-mask_hw[plen], 0], y=[0,0], pen='2p,black,.')\n",
    "    fig.plot(x=[0, mask_hw[plen]], y=[asc_offset,asc_offset], pen='2p,black,.')\n",
    "    fig.plot(x=[mask_hw[plen],box_hw[plen]], y=[asc_offset,asc_offset], pen='2p,black,-')\n",
    "\n",
    "\n",
    "    fig.shift_origin(xshift=\"14c\")                                                # shift the origin\n",
    "    fig.basemap(region=dbox, projection=\"X12c/6c\", frame=['xa1f0.2+l\"distance (km)\"','ya10f2','WeSn'])  # make a basemap frame\n",
    "    fig.text(text='{0:s}, {1:4.1f} +/- {2:3.1f}'.format(dsc_tr,dsc_offset,2*sigma_dsc_offset), position=\"TL\", font=\"14p\", \n",
    "         offset=\"0.2c/-0.2c\", justify=\"TL\") # label the plot\n",
    "    fig.text(text='rms: {0:4.1f}'.format(rms_dsc), position=\"TR\", font=\"14p\", offset=\"-0.2c/-0.2c\", justify=\"TR\") \n",
    "    fig.text(text=\"creep: {0:4.1f} +/- {1:3.1f}\".format(h_offset[0],2*sigma_h_offset), position=\"BR\", font=\"14p\", \n",
    "         offset=\"-0.2c/0.2c\", justify=\"BR\") # label the plot\n",
    "    fig.plot(x=samp_pts[\"P\"], y=samp_pts[dsc_tr]-m_dsc[0]*samp_pts[\"P\"]-m_dsc[1], style=\"c0.1c\", color=\"orange\")  # detrended vels\n",
    "    fig.plot(x=[-box_hw[plen],-mask_hw[plen]], y=[0,0], pen='2p,black,-')\n",
    "    fig.plot(x=[-mask_hw[plen],0], y=[0,0], pen='2p,black,.')\n",
    "    fig.plot(x=[0,mask_hw[plen]], y=[dsc_offset,dsc_offset], pen='2p,black,.')\n",
    "    fig.plot(x=[mask_hw[plen],box_hw[plen]], y=[dsc_offset,dsc_offset], pen='2p,black,-')\n",
    "\n",
    "\n",
    "    figfile=\"profile_{0:s}_{1:s}_distance_{2:06.2f}_{3:f}_{4:f}.png\".format(asc_tr,dsc_tr,as_distance,box_hw[plen],mask_hw[plen])\n",
    "    #print(figfile)\n",
    "    #fig.show(width=800)\n",
    "    fig.savefig(figfile)\n",
    "    \n",
    "    # and record the results\n",
    "    creep_rates.loc[i][\"{0:s}_offset\".format(asc_tr)]=asc_offset\n",
    "    creep_rates.loc[i][\"{0:s}_sigma\".format(asc_tr)]=sigma_asc_offset\n",
    "    creep_rates.loc[i][\"{0:s}_rms\".format(asc_tr)]=rms_asc\n",
    "    creep_rates.loc[i][\"{0:s}_offset\".format(dsc_tr)]=dsc_offset\n",
    "    creep_rates.loc[i][\"{0:s}_sigma\".format(dsc_tr)]=sigma_dsc_offset\n",
    "    creep_rates.loc[i][\"{0:s}_rms\".format(dsc_tr)]=rms_dsc\n",
    "    creep_rates.loc[i][\"fp_offset\"]=h_offset[0]\n",
    "    creep_rates.loc[i][\"fp_sigma\"]=sigma_h_offset\n",
    "    creep_rates.loc[i][\"v_offset\"]=v_offset[0]\n",
    "    creep_rates.loc[i][\"v_sigma\"]=sigma_v_offset\n",
    "\n",
    "# let's save these as a text file!\n",
    "creep_rates.to_csv('{0:s}_{1:s}_creep_rates_{2:f}_{3:f}.dat'.format(asc_tr,dsc_tr,box_hw[plen],mask_hw[plen]),\n",
    "                   sep=\" \",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "creep_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's plot the output\n",
    "\n",
    "# (you may need to change these bounding boxes based on the fault length and profile values)\n",
    "\n",
    "fp_box=[0, 200, -5, 35]\n",
    "v_box=[0, 200, -5, 15]\n",
    "asc_box=[0, 200, -15, 10]\n",
    "dsc_box=[0, 200, -3, 22]\n",
    "\n",
    "fig = pygmt.Figure() \n",
    "\n",
    "\n",
    "fig.basemap(region=fp_box, projection=\"X24c/5c\", \n",
    "            frame=['xa10f2','ya10f2+l\"creep rate (mm/yr)\"',\"Wesn\"]) \n",
    "fig.plot(data=creep_rates[[\"distance\",\"fp_offset\",\"fp_sigma\"]].values, error_bar=\"y+pfaint,gray50\", style=\"t0.4c\", \n",
    "         color=\"darkred\",pen=\"faint\", no_clip=True)   # creep rates\n",
    "    \n",
    "fig.shift_origin(yshift=\"-3.3c\")                                                # shift the origin\n",
    "fig.basemap(region=v_box, projection=\"X24c/2.5c\", \n",
    "            frame=['xa10f2','ya10f2+l\"vertical (mm/yr)\"',\"Wesn\"]) \n",
    "fig.plot(data=creep_rates[[\"distance\",\"v_offset\",\"v_sigma\"]].values, error_bar=\"y+pfaint,gray50\", style=\"t0.4c\", \n",
    "         color=\"hotpink\",pen=\"faint\", no_clip=True)   # creep rates\n",
    "\n",
    "\n",
    "fig.shift_origin(yshift=\"-3.8c\")                                                # shift the origin\n",
    "fig.basemap(region=asc_box, projection=\"X24c/3c\", \n",
    "            frame=['xa10f2','ya10f2+l\"asc (mm/yr)\"',\"Wesn\"]) \n",
    "fig.plot(data=creep_rates[[\"distance\",\"{0:s}_offset\".format(asc_tr),\"{0:s}_sigma\".format(asc_tr)]].values, \n",
    "         error_bar=\"y+pfaint,gray50\", style=\"s0.4c\", color=\"cyan\", pen=\"faint\", no_clip=True)   # offset rates\n",
    "\n",
    "fig.shift_origin(yshift=\"-3.8c\")                                                # shift the origin\n",
    "fig.basemap(region=dsc_box, projection=\"X24c/3c\", \n",
    "            frame=['xa10f2+l\"distance from San Juan Bautista (km)\"','ya10f2+l\"dsc (mm/yr)\"',\"WeSn\"]) \n",
    "fig.plot(data=creep_rates[[\"distance\",\"{0:s}_offset\".format(dsc_tr),\"{0:s}_sigma\".format(dsc_tr)]].values, \n",
    "         error_bar=\"y+pfaint,gray50\", style=\"s0.4c\", color=\"orange\", pen=\"faint\", no_clip=True)   # offset rates\n",
    "\n",
    "\n",
    "#fig.text(text='{0:s}, {1:4.1f} +/- {2:3.1f}'.format(asc_tr,asc_offset,2*sigma_asc_offset), position=\"TL\", font=\"14p\", \n",
    "#         offset=\"0.2c/-0.2c\", justify=\"TL\") # label the plot\n",
    "#fig.text(text=\"profile {0:d}\".format(prof_num), position=\"BL\", font=\"14p\", offset=\"0.2c\", justify=\"BL\") # label the plot\n",
    "    \n",
    "#fig.plot([-box_hw, -mask_hw],[0,0], pen='2p,black,-')\n",
    "#fig.plot([-mask_hw, 0],[0,0], pen='2p,black,.')\n",
    "#fig.plot([0, mask_hw],[asc_offset,asc_offset], pen='2p,black,.')\n",
    "#fig.plot([mask_hw, box_hw],[asc_offset,asc_offset], pen='2p,black,-')\n",
    "\n",
    "fig.savefig('summary_creep_rate_{0:s}_{1:s}.png'.format(asc_tr,dsc_tr))\n",
    "fig.show(width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"other\"></a>8. Other outputs\n",
    "\n",
    "Useful for plotting purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we probably want to output the profile lines \n",
    "\n",
    "prof_dx=np.sin(np.radians(fault_strike-90))\n",
    "prof_dy=np.cos(np.radians(fault_strike-90))\n",
    "\n",
    "\n",
    "# the end coordinates in utm\n",
    "x1_utm=fault_segs[\"x\"]-(box_hw*1000)*np.sin(np.radians(fault_segs[\"strike\"]-90))\n",
    "y1_utm=fault_segs[\"y\"]-(box_hw*1000)*np.cos(np.radians(fault_segs[\"strike\"]-90))\n",
    "x2_utm=fault_segs[\"x\"]+(box_hw*1000)*np.sin(np.radians(fault_segs[\"strike\"]-90))\n",
    "y2_utm=fault_segs[\"y\"]+(box_hw*1000)*np.cos(np.radians(fault_segs[\"strike\"]-90))\n",
    "\n",
    "# project!\n",
    "x1y1_ll=utm.to_latlon(x1_utm,y1_utm,utm_zone,utm_letter)\n",
    "x2y2_ll=utm.to_latlon(x2_utm,y2_utm,utm_zone,utm_letter)\n",
    "\n",
    "# new dataframe\n",
    "profile_lines=pd.DataFrame({'x1': x1y1_ll[1], 'y1': x1y1_ll[0], 'xc': fault_segs[\"longitude\"], 'yc': fault_segs[\"latitude\"], \n",
    "                            'x2': x2y2_ll[1], 'y2': x2y2_ll[0], 'distance': fault_segs[\"distance\"], \n",
    "                            'strike': fault_segs[\"strike\"]})\n",
    "\n",
    "# and write it out\n",
    "prof_lines_file='profile_lines_{0:s}_{1:s}.xy'.format(asc_tr,dsc_tr)\n",
    "profile_lines.to_csv(prof_lines_file,sep=\" \",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't seem to work\n",
    "!awk '{if (NR>1) printf(\"> -L\\\"%06.2f\\\" -T\\\"profile %02d\\\"\\n %f %f\\n %f %f\\n\", $7, NR-2, $1, $2, $5, $6)}' $prof_lines_file | gmt gmt2kml -Fl -Wthick,white > $prof_lines_file.kml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a>9. References\n",
    "\n",
    "The method used in this notebook is based on that of [Lin and Funning, 2017](https://drive.google.com/file/d/1Ji_AZCl7SJNUMAIrUBC5GApPwBggbKhZ/view), although the exact math for computing the unit pointing vector is a little different as Sentinel-1 and ISCE made it more complicated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
